{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# pd.set_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YG</td>\n",
       "      <td>BAND DRUM (feat. A$AP Rocky)</td>\n",
       "      <td>I mix the 4Hunnid with the designer  Stay lace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chris Cooq</td>\n",
       "      <td>Lactose</td>\n",
       "      <td>I came to rule this stage with that Budden swa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chris Cooq</td>\n",
       "      <td>Same - Original mix</td>\n",
       "      <td>Gorillaz - Song Machine Episode 7 - 4/4  mxmto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Curbo</td>\n",
       "      <td>Debauchery - Original mix</td>\n",
       "      <td>Learning is, indeed, a very great and a very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G Herbo</td>\n",
       "      <td>Bon appétit</td>\n",
       "      <td>Young nigga eatin', uh, bon appetit, uh  Messe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artist                          song  \\\n",
       "0          YG  BAND DRUM (feat. A$AP Rocky)   \n",
       "1  Chris Cooq                       Lactose   \n",
       "2  Chris Cooq           Same - Original mix   \n",
       "3       Curbo     Debauchery - Original mix   \n",
       "4     G Herbo                   Bon appétit   \n",
       "\n",
       "                                              lyrics  \n",
       "0  I mix the 4Hunnid with the designer  Stay lace...  \n",
       "1  I came to rule this stage with that Budden swa...  \n",
       "2  Gorillaz - Song Machine Episode 7 - 4/4  mxmto...  \n",
       "3    Learning is, indeed, a very great and a very...  \n",
       "4  Young nigga eatin', uh, bon appetit, uh  Messe...  "
      ]
     },
     "execution_count": 47,
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bad songs dataframe\n",
    "bad_songs = pd.read_csv('datasets/bad_cleaned2.csv')\n",
    "bad_songs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sam the sham and the pharaohs</td>\n",
       "      <td>wooly bully</td>\n",
       "      <td>sam the sham miscellaneous wooly bully wooly b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>four tops</td>\n",
       "      <td>i cant help myself sugar pie honey bunch</td>\n",
       "      <td>sugar pie honey bunch you know that i love yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we five</td>\n",
       "      <td>you were on my mind</td>\n",
       "      <td>when i woke up this morning you were on my mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the righteous brothers</td>\n",
       "      <td>youve lost that lovin feelin</td>\n",
       "      <td>you never close your eyes anymore when i kiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petula clark</td>\n",
       "      <td>downtown</td>\n",
       "      <td>when youre alone and life is making you lonel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          artist                                      song  \\\n",
       "0  sam the sham and the pharaohs                               wooly bully   \n",
       "1                      four tops  i cant help myself sugar pie honey bunch   \n",
       "2                        we five                       you were on my mind   \n",
       "3         the righteous brothers              youve lost that lovin feelin   \n",
       "4                   petula clark                                  downtown   \n",
       "\n",
       "                                              lyrics  \n",
       "0  sam the sham miscellaneous wooly bully wooly b...  \n",
       "1   sugar pie honey bunch you know that i love yo...  \n",
       "2   when i woke up this morning you were on my mi...  \n",
       "3   you never close your eyes anymore when i kiss...  \n",
       "4   when youre alone and life is making you lonel...  "
      ]
     },
     "execution_count": 48,
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# good songs dataframe\n",
    "good_songs = pd.read_csv('datasets/good_cleaned.csv')\n",
    "good_songs = good_songs[['artist','song','lyrics']].copy()\n",
    "good_songs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined dataframe\n",
    "main = pd.concat([good_songs, bad_songs], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning \n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    cleaned_text = re.sub(r'[.,!?\\\\-]', '', text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "main['lyrics'] = main['lyrics'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sam the sham and the pharaohs</td>\n",
       "      <td>wooly bully</td>\n",
       "      <td>sam the sham miscellaneous wooly bully wooly b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>four tops</td>\n",
       "      <td>i cant help myself sugar pie honey bunch</td>\n",
       "      <td>sugar pie honey bunch you know that i love yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we five</td>\n",
       "      <td>you were on my mind</td>\n",
       "      <td>when i woke up this morning you were on my mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the righteous brothers</td>\n",
       "      <td>youve lost that lovin feelin</td>\n",
       "      <td>you never close your eyes anymore when i kiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petula clark</td>\n",
       "      <td>downtown</td>\n",
       "      <td>when youre alone and life is making you lonel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8334</th>\n",
       "      <td>King John</td>\n",
       "      <td>Mismatched</td>\n",
       "      <td>Weve been dispatched by God sent to warn these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8335</th>\n",
       "      <td>Buck Meek</td>\n",
       "      <td>Cannonball!</td>\n",
       "      <td>Beats me down by the pool sweet Suzy summers g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8336</th>\n",
       "      <td>Big Beats</td>\n",
       "      <td>Young Forever (Instrumental)</td>\n",
       "      <td>Proving himself in the booth was just the be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8337</th>\n",
       "      <td>Big Beats</td>\n",
       "      <td>Escape (Instrumental)</td>\n",
       "      <td>Im just me I cant be different  Though I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8338</th>\n",
       "      <td>Nathan K.</td>\n",
       "      <td>If I Die</td>\n",
       "      <td>Yes sir know what Im talkin bout  Legendary ye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8339 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             artist                                      song  \\\n",
       "0     sam the sham and the pharaohs                               wooly bully   \n",
       "1                         four tops  i cant help myself sugar pie honey bunch   \n",
       "2                           we five                       you were on my mind   \n",
       "3            the righteous brothers              youve lost that lovin feelin   \n",
       "4                      petula clark                                  downtown   \n",
       "...                             ...                                       ...   \n",
       "8334                      King John                                Mismatched   \n",
       "8335                      Buck Meek                               Cannonball!   \n",
       "8336                      Big Beats              Young Forever (Instrumental)   \n",
       "8337                      Big Beats                     Escape (Instrumental)   \n",
       "8338                      Nathan K.                                  If I Die   \n",
       "\n",
       "                                                 lyrics  \n",
       "0     sam the sham miscellaneous wooly bully wooly b...  \n",
       "1      sugar pie honey bunch you know that i love yo...  \n",
       "2      when i woke up this morning you were on my mi...  \n",
       "3      you never close your eyes anymore when i kiss...  \n",
       "4      when youre alone and life is making you lonel...  \n",
       "...                                                 ...  \n",
       "8334  Weve been dispatched by God sent to warn these...  \n",
       "8335  Beats me down by the pool sweet Suzy summers g...  \n",
       "8336    Proving himself in the booth was just the be...  \n",
       "8337        Im just me I cant be different  Though I...  \n",
       "8338  Yes sir know what Im talkin bout  Legendary ye...  \n",
       "\n",
       "[8339 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result = main['lyrics'].str.contains('\\.').sum()\n",
    "main"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''splitting'''\n",
    "# Create a new column 'label' with 1 for good songs and 0 for bad songs\n",
    "main['label'] = (main['lyrics'].isin(good_songs['lyrics'])) * 1\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(main['lyrics'], main['label'], random_state=42)\n",
    "\n",
    "y_test = y_test.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with n-gram length 1: 0.9851294644284574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with n-gram length 1: 0.9908872901678657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with n-gram length 2: 0.9884874180655476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with n-gram length 2: 0.9932853717026379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with n-gram length 3: 0.9881676738609114\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kubad\\Documents\\GitHub\\BDA_song_hits\\bag_of_words.ipynb Cell 8\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kubad/Documents/GitHub/BDA_song_hits/bag_of_words.ipynb#X31sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAccuracy with n-gram length \u001b[39m\u001b[39m{\u001b[39;00mn\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mmean_accuracy\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kubad/Documents/GitHub/BDA_song_hits/bag_of_words.ipynb#X31sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Fit the logistic regression model on the full training data and evaluate on the test data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kubad/Documents/GitHub/BDA_song_hits/bag_of_words.ipynb#X31sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m lr\u001b[39m.\u001b[39;49mfit(text_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kubad/Documents/GitHub/BDA_song_hits/bag_of_words.ipynb#X31sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m test_accuracy \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39mscore(text_test, y_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kubad/Documents/GitHub/BDA_song_hits/bag_of_words.ipynb#X31sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTest Accuracy with n-gram length \u001b[39m\u001b[39m{\u001b[39;00mn\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mtest_accuracy\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1233\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1231\u001b[0m     n_threads \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1233\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, prefer\u001b[39m=\u001b[39;49mprefer)(\n\u001b[0;32m   1234\u001b[0m     path_func(\n\u001b[0;32m   1235\u001b[0m         X,\n\u001b[0;32m   1236\u001b[0m         y,\n\u001b[0;32m   1237\u001b[0m         pos_class\u001b[39m=\u001b[39;49mclass_,\n\u001b[0;32m   1238\u001b[0m         Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[0;32m   1239\u001b[0m         l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[0;32m   1240\u001b[0m         fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[0;32m   1241\u001b[0m         tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m   1242\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1243\u001b[0m         solver\u001b[39m=\u001b[39;49msolver,\n\u001b[0;32m   1244\u001b[0m         multi_class\u001b[39m=\u001b[39;49mmulti_class,\n\u001b[0;32m   1245\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1246\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m   1247\u001b[0m         check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1248\u001b[0m         random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[0;32m   1249\u001b[0m         coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[0;32m   1250\u001b[0m         penalty\u001b[39m=\u001b[39;49mpenalty,\n\u001b[0;32m   1251\u001b[0m         max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[0;32m   1252\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1253\u001b[0m         n_threads\u001b[39m=\u001b[39;49mn_threads,\n\u001b[0;32m   1254\u001b[0m     )\n\u001b[0;32m   1255\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef)\n\u001b[0;32m   1256\u001b[0m )\n\u001b[0;32m   1258\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1259\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:436\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    432\u001b[0m l2_reg_strength \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m C\n\u001b[0;32m    433\u001b[0m iprint \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m101\u001b[39m][\n\u001b[0;32m    434\u001b[0m     np\u001b[39m.\u001b[39msearchsorted(np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]), verbose)\n\u001b[0;32m    435\u001b[0m ]\n\u001b[1;32m--> 436\u001b[0m opt_res \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39;49mminimize(\n\u001b[0;32m    437\u001b[0m     func,\n\u001b[0;32m    438\u001b[0m     w0,\n\u001b[0;32m    439\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    440\u001b[0m     jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    441\u001b[0m     args\u001b[39m=\u001b[39;49m(X, target, sample_weight, l2_reg_strength, n_threads),\n\u001b[0;32m    442\u001b[0m     options\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39miprint\u001b[39;49m\u001b[39m\"\u001b[39;49m: iprint, \u001b[39m\"\u001b[39;49m\u001b[39mgtol\u001b[39;49m\u001b[39m\"\u001b[39;49m: tol, \u001b[39m\"\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_iter},\n\u001b[0;32m    443\u001b[0m )\n\u001b[0;32m    444\u001b[0m n_iter_i \u001b[39m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    445\u001b[0m     solver,\n\u001b[0;32m    446\u001b[0m     opt_res,\n\u001b[0;32m    447\u001b[0m     max_iter,\n\u001b[0;32m    448\u001b[0m     extra_warning_msg\u001b[39m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    449\u001b[0m )\n\u001b[0;32m    450\u001b[0m w0, loss \u001b[39m=\u001b[39m opt_res\u001b[39m.\u001b[39mx, opt_res\u001b[39m.\u001b[39mfun\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\optimize\\_minimize.py:699\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    696\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    697\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    698\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 699\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    700\u001b[0m                            callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    701\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    702\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[0;32m    703\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:362\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    356\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[0;32m    357\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    358\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    360\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 362\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[0;32m    363\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    364\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[0;32m    365\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[0;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[0;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[0;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\optimize\\_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[0;32m     75\u001b[0m     \u001b[39m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\optimize\\_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 70\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[0;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:200\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads)\u001b[0m\n\u001b[0;32m    198\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m l2_reg_strength \u001b[39m*\u001b[39m (weights \u001b[39m@\u001b[39m weights)\n\u001b[0;32m    199\u001b[0m grad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty_like(coef, dtype\u001b[39m=\u001b[39mweights\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m--> 200\u001b[0m grad[:n_features] \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mT \u001b[39m@\u001b[39;49m grad_per_sample \u001b[39m+\u001b[39m l2_reg_strength \u001b[39m*\u001b[39m weights\n\u001b[0;32m    201\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_intercept:\n\u001b[0;32m    202\u001b[0m     grad[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m grad_per_sample\u001b[39m.\u001b[39msum()\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_base.py:630\u001b[0m, in \u001b[0;36mspmatrix.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    628\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mScalar operands are not allowed, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    629\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39muse \u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 630\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mul_dispatch(other)\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_base.py:528\u001b[0m, in \u001b[0;36mspmatrix._mul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[39mif\u001b[39;00m other\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m    526\u001b[0m     \u001b[39m# Fast path for the most common case\u001b[39;00m\n\u001b[0;32m    527\u001b[0m     \u001b[39mif\u001b[39;00m other\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (N,):\n\u001b[1;32m--> 528\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mul_vector(other)\n\u001b[0;32m    529\u001b[0m     \u001b[39melif\u001b[39;00m other\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (N, \u001b[39m1\u001b[39m):\n\u001b[0;32m    530\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mul_vector(other\u001b[39m.\u001b[39mravel())\u001b[39m.\u001b[39mreshape(M, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_compressed.py:489\u001b[0m, in \u001b[0;36m_cs_matrix._mul_vector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[39m# csr_matvec or csc_matvec\u001b[39;00m\n\u001b[0;32m    488\u001b[0m fn \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(_sparsetools, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_matvec\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 489\u001b[0m fn(M, N, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindptr, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, other, result)\n\u001b[0;32m    491\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the n-gram lengths to evaluate\n",
    "ngram_lengths = [1, 2, 3]  # Example: Unigrams, Bigrams, Trigrams\n",
    "\n",
    "# Iterate over different n-gram lengths\n",
    "for n in ngram_lengths:\n",
    "    # Create the CountVectorizer with the specified n-gram length\n",
    "    vect = CountVectorizer(min_df=5, ngram_range=(1, n))\n",
    "\n",
    "    # Apply tokenization and vectorization on the 'lyrics' column\n",
    "    text_train = vect.fit_transform(X_train)\n",
    "    text_test = vect.transform(X_test)\n",
    "\n",
    "    # Create a logistic regression model\n",
    "    lr = LogisticRegression()\n",
    "\n",
    "    # Perform cross-validation on the training data and compute the mean accuracy\n",
    "    scores = cross_val_score(lr, text_train, y_train, cv=5)\n",
    "    mean_accuracy = scores.mean()\n",
    "\n",
    "    # Print the results for the current n-gram length\n",
    "    print(f\"Accuracy with n-gram length {n}: {mean_accuracy}\")\n",
    "\n",
    "    # Fit the logistic regression model on the full training data and evaluate on the test data\n",
    "    lr.fit(text_train, y_train)\n",
    "    test_accuracy = lr.score(text_test, y_test)\n",
    "    print(f\"Test Accuracy with n-gram length {n}: {test_accuracy}\")\n",
    "\n",
    "# n-gram = 1: accuracy 0.9851294644284574, test accuracy 0.9908872901678657\n",
    "# n-gram = 2: accuracy 0.9884874180655476, test accuracy 0.9932853717026379\n",
    "# n-gram = 3: accuracy 0.9881676738609114, test accuracy "
=======
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "833"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.set_option('display.max_colwidth')\n",
    "result = main['lyrics'].str.contains('feat').sum()\n",
    "result"
>>>>>>> 72207120f3337917614fef53e3fa60e634e0c8ec
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''applying bag of words'''\n",
    "\n",
    "# Create a CountVectorizer object\n",
    "vect = CountVectorizer() #(min_df=5)\n",
    "\n",
    "text_train = vect.fit_transform(X_train)\n",
    "text_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\elits\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\elits\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the English stop words from NLTK\n",
    "nltk.download('stopwords')\n",
    "english_stop_words = stopwords.words('english')\n",
    "\n",
    "# Get the Spanish stop words from NLTK\n",
    "nltk.download('stopwords')\n",
    "spanish_stop_words = stopwords.words('spanish')\n",
    "\n",
    "# Combine the stop words into a single list\n",
    "stop_words = english_stop_words + spanish_stop_words\n",
    "\n",
    "# Create a CountVectorizer object with stop words\n",
    "vect = CountVectorizer(min_df=5, stop_words=stop_words)\n",
    "\n",
    "# Fit and transform the training data\n",
    "text_train = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elits\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the feature names (words) from the CountVectorizer\n",
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "# Calculate the word frequencies in the training set\n",
    "word_frequencies = text_train.sum(axis=0)\n",
    "\n",
    "# Create a dictionary with words as keys and their corresponding frequencies as values\n",
    "word_freq_dict = dict(zip(feature_names, word_frequencies.tolist()[0]))\n",
    "\n",
    "# Sort the dictionary by word frequencies in descending order\n",
    "sorted_word_freq = sorted(word_freq_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Extract the top 50 words and their frequencies\n",
    "top_words = [item[0] for item in sorted_word_freq[:50]]\n",
    "top_freqs = [item[1] for item in sorted_word_freq[:50]]\n",
    "\n",
    "# Plot the top 50 words and their frequencies\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.bar(top_words, top_freqs)\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequencies')\n",
    "plt.title('Top 50 Words in Bag-of-Words Representation')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
>>>>>>> 72207120f3337917614fef53e3fa60e634e0c8ec
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_train:\n",
      "<6675x278978 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3696204 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "print(\"text_train:\\n{}\".format(repr(text_train)))\n",
    "#shape of our text_train is 8106x327664 - vocabulary contains 327664 entries (features) stored as SciPy sparse matrix\n",
    "#shape after constraint to have appearance in at least 5 documents, shrinks to 108184 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9886159376872379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kubad\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Create a logistic regression object and fit the model on the training data\n",
    "lr = LogisticRegression()\n",
    "lr.fit(text_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "score = lr.score(text_test, y_test)\n",
    "print(\"Accuracy:\", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
